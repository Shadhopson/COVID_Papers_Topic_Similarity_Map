{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6424adb",
   "metadata": {},
   "source": [
    "## Initialize the Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include any needed imports\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28af61b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder.master(\"local\")\n",
    "                             .config(\"spark.jars\", \"/usr/share/java/mysql-connector-java-8.0.23.jar\")\n",
    "                             .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure MySQL Connection\n",
    "sqlEngine = create_engine('mysql+pymysql://root:p@ssw0rd1@cse6242_team094_mysqldb/cse6242_team094')\n",
    "dbConnection = sqlEngine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a2c3b",
   "metadata": {},
   "source": [
    "## Load in the Output from 01-PySpark_Lemmatization.ipynb\n",
    "\n",
    "The output of this notebook consists of 3 tables: 1) abstracts, 2) metadata, and 3) titles. Within the `/data_processing/aws_data` folder on the host machine, you should have placed the Parquet files retrieved from the AWS S3 Bucket, as outlined in the Readme instructions.\n",
    "\n",
    "**Important:** This code assumes you already have the local MySQL Docker Container running according to the instructions mentioned in the Readme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2424f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load \"titles\" from Parquet\n",
    "abstracts_df = spark.read.parquet(\"./aws_data/01-abstracts\")\n",
    "\n",
    "# Write to MySQL\n",
    "(abstracts_df.write\n",
    "               .format('jdbc')\n",
    "               .options(url=\"jdbc:mysql://cse6242_team094_mysqldb/cse6242_team094?sessionVariables=sql_mode='NO_ENGINE_SUBSTITUTION'&jdbcCompliantTruncation=false\",\n",
    "                        driver='com.mysql.jdbc.Driver',\n",
    "                        dbtable='processed_abstracts',\n",
    "                        user='root',\n",
    "                        password='p@ssw0rd1',\n",
    "                        createTableColumnTypes='abstract VARCHAR(65536), cord_uid VARCHAR(1024), abstract_tokens VARCHAR(65536)')\n",
    "               .mode('overwrite')\n",
    "               .save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3125198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load \"titles\" from Parquet\n",
    "titles_df = spark.read.parquet(\"./aws_data/01-titles\")\n",
    "\n",
    "# Write to MySQL\n",
    "(titles_df.write\n",
    "           .format('jdbc')\n",
    "           .options(url='jdbc:mysql://cse6242_team094_mysqldb/cse6242_team094',\n",
    "                    driver='com.mysql.jdbc.Driver',\n",
    "                    dbtable='titles',\n",
    "                    user='root',\n",
    "                    password='p@ssw0rd1')\n",
    "           .mode('overwrite')\n",
    "           .save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1c5adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load \"titles\" from Parquet\n",
    "metadata_df = spark.read.parquet(\"./aws_data/01-metadata\")\n",
    "\n",
    "# Write to MySQL\n",
    "(metadata_df.write\n",
    "           .format('jdbc')\n",
    "           .options(url='jdbc:mysql://cse6242_team094_mysqldb/cse6242_team094',\n",
    "                    driver='com.mysql.jdbc.Driver',\n",
    "                    dbtable='metadata',\n",
    "                    user='root',\n",
    "                    password='p@ssw0rd1')\n",
    "           .mode('overwrite')\n",
    "           .save())"
   ]
  },
  {
   "source": [
    "## Load in the Output from 02a-BERTopic.ipynb\n",
    "\n",
    "The output of this notebook consists of 4 tables. Within the `/data_processing/aws_data` folder on the host machine, you should have placed the CSV files retrieved from the AWS EC2 instance, as outlined in the Readme instructions.\n",
    "\n",
    "**Important:** This code assumes you already have the local MySQL Docker Container running according to the instructions mentioned in the Readme."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV\n",
    "bert_string_doc_to_topic_pd_df = pd.read_csv(\"./aws_data/02a-bert-string-doc-to-topic/string_doc_to_topic.csv\")\n",
    "bert_string_doc_to_topic_spark_df = (spark.createDataFrame(bert_string_doc_to_topic_pd_df)\n",
    "                                            .drop(\"Unnamed: 0\"))\n",
    "\n",
    "# Write to MySQL\n",
    "(bert_string_doc_to_topic_spark_df.write\n",
    "                                .format('jdbc')\n",
    "                                .options(url=\"jdbc:mysql://cse6242_team094_mysqldb/cse6242_team094?sessionVariables=sql_mode='NO_ENGINE_SUBSTITUTION'&jdbcCompliantTruncation=false\",\n",
    "                                            driver='com.mysql.jdbc.Driver',\n",
    "                                            dbtable='02a_bert_string_doc_to_topic',\n",
    "                                            user='root',\n",
    "                                            password='p@ssw0rd1')\n",
    "                                .mode('overwrite')\n",
    "                                .save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV\n",
    "bert_doc_to_topic_pd_df = pd.read_csv(\"./aws_data/02a-bert-doc-to-topic/doc_topic_df.csv\")\n",
    "bert_doc_to_topic_spark_df = (spark.createDataFrame(bert_doc_to_topic_pd_df)\n",
    "                                            .drop(\"Unnamed: 0\"))\n",
    "\n",
    "# Write to MySQL\n",
    "(bert_doc_to_topic_spark_df.write\n",
    "                                .format('jdbc')\n",
    "                                .options(url=\"jdbc:mysql://cse6242_team094_mysqldb/cse6242_team094?sessionVariables=sql_mode='NO_ENGINE_SUBSTITUTION'&jdbcCompliantTruncation=false\",\n",
    "                                            driver='com.mysql.jdbc.Driver',\n",
    "                                            dbtable='02a_bert_doc_topic',\n",
    "                                            user='root',\n",
    "                                            password='p@ssw0rd1')\n",
    "                                .mode('overwrite')\n",
    "                                .save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV\n",
    "bert_extended_topic_pd_df = pd.read_csv(\"./aws_data/02a-bert-extended-topic/extended_topic_df.csv\")\n",
    "bert_extended_topic_spark_df = (spark.createDataFrame(bert_extended_topic_pd_df)\n",
    "                                     .drop(\"Unnamed: 0\"))\n",
    "\n",
    "# Write to MySQL\n",
    "(bert_extended_topic_spark_df.write\n",
    "                           .format('jdbc')\n",
    "                           .options(url=\"jdbc:mysql://cse6242_team094_mysqldb/cse6242_team094?sessionVariables=sql_mode='NO_ENGINE_SUBSTITUTION'&jdbcCompliantTruncation=false\",\n",
    "                                    driver='com.mysql.jdbc.Driver',\n",
    "                                    dbtable='02a_bert_extended_topic',\n",
    "                                    user='root',\n",
    "                                    password='p@ssw0rd1')\n",
    "                           .mode('overwrite')\n",
    "                           .save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV\n",
    "bert_string_topic_to_words_pd_df = pd.read_csv(\"./aws_data/02a-bert-string-topic-to-words/string_topic_to_words.csv\")\n",
    "bert_string_topic_to_words_spark_df = (spark.createDataFrame(bert_string_topic_to_words_pd_df)\n",
    "                                            .drop(\"Unnamed: 0\"))\n",
    "\n",
    "# Write to MySQL\n",
    "(bert_string_topic_to_words_spark_df.write\n",
    "                                    .format('jdbc')\n",
    "                                    .options(url=\"jdbc:mysql://cse6242_team094_mysqldb/cse6242_team094?sessionVariables=sql_mode='NO_ENGINE_SUBSTITUTION'&jdbcCompliantTruncation=false\",\n",
    "                                                driver='com.mysql.jdbc.Driver',\n",
    "                                                dbtable='02a_bert_string_topic_to_words',\n",
    "                                                user='root',\n",
    "                                                password='p@ssw0rd1')\n",
    "                                    .mode('overwrite')\n",
    "                                    .save())"
   ]
  },
  {
   "source": [
    "## Load in the Output from 02b-LDA.ipynb\n",
    "\n",
    "The output of this notebook consists of 4 tables. Within the `/data_processing/aws_data` folder on the host machine, you should have placed the CSV files retrieved from the AWS EC2 instance, as outlined in the Readme instructions.\n",
    "\n",
    "**Important:** This code assumes you already have the local MySQL Docker Container running according to the instructions mentioned in the Readme."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV\n",
    "lda_string_doc_to_topic_pd_df = pd.read_csv(\"./aws_data/02b-lda-string-doc-to-topic/string_lda_doc_to_topic.csv\")\n",
    "lda_string_doc_to_topic_spark_df = (spark.createDataFrame(lda_string_doc_to_topic_pd_df)\n",
    "                                         .drop(\"Unnamed: 0\"))\n",
    "\n",
    "# Write to MySQL\n",
    "(lda_string_doc_to_topic_spark_df.write\n",
    "                                .format('jdbc')\n",
    "                                .options(url=\"jdbc:mysql://cse6242_team094_mysqldb/cse6242_team094?sessionVariables=sql_mode='NO_ENGINE_SUBSTITUTION'&jdbcCompliantTruncation=false\",\n",
    "                                            driver='com.mysql.jdbc.Driver',\n",
    "                                            dbtable='02b_lda_string_doc_to_topic',\n",
    "                                            user='root',\n",
    "                                            password='p@ssw0rd1')\n",
    "                                .mode('overwrite')\n",
    "                                .save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV\n",
    "lda_doc_to_topic_pd_df = pd.read_csv(\"./aws_data/02b-lda-doc-to-topic/lda_doc_to_topic.csv\")\n",
    "lda_doc_to_topic_spark_df = (spark.createDataFrame(lda_doc_to_topic_pd_df)\n",
    "                                  .drop(\"Unnamed: 0\"))\n",
    "\n",
    "# Write to MySQL\n",
    "(lda_doc_to_topic_spark_df.write\n",
    "                            .format('jdbc')\n",
    "                            .options(url=\"jdbc:mysql://cse6242_team094_mysqldb/cse6242_team094?sessionVariables=sql_mode='NO_ENGINE_SUBSTITUTION'&jdbcCompliantTruncation=false\",\n",
    "                                        driver='com.mysql.jdbc.Driver',\n",
    "                                        dbtable='02b_lda_doc_to_topic',\n",
    "                                        user='root',\n",
    "                                        password='p@ssw0rd1')\n",
    "                            .mode('overwrite')\n",
    "                            .save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV\n",
    "lda_string_topic_to_words_pd_df = pd.read_csv(\"./aws_data/02b-lda-string-topic-to-words/lda_string_topic_to_words.csv\")\n",
    "lda_string_topic_to_words_spark_df = (spark.createDataFrame(lda_string_topic_to_words_pd_df)\n",
    "                                         .drop(\"Unnamed: 0\"))\n",
    "\n",
    "# Write to MySQL\n",
    "(lda_string_topic_to_words_spark_df.write\n",
    "                                    .format('jdbc')\n",
    "                                    .options(url=\"jdbc:mysql://cse6242_team094_mysqldb/cse6242_team094?sessionVariables=sql_mode='NO_ENGINE_SUBSTITUTION'&jdbcCompliantTruncation=false\",\n",
    "                                                driver='com.mysql.jdbc.Driver',\n",
    "                                                dbtable='02b_lda_string_topic_to_words',\n",
    "                                                user='root',\n",
    "                                                password='p@ssw0rd1')\n",
    "                                    .mode('overwrite')\n",
    "                                    .save())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV\n",
    "lda_topic_to_words_pd_df = pd.read_csv(\"./aws_data/02b-lda-topic-to-words/lda_topic_to_words.csv\")\n",
    "lda_topic_to_words_spark_df = (spark.createDataFrame(lda_topic_to_words_pd_df)\n",
    "                                  .drop(\"Unnamed: 0\"))\n",
    "\n",
    "# Write to MySQL\n",
    "(lda_topic_to_words_spark_df.write\n",
    "                            .format('jdbc')\n",
    "                            .options(url=\"jdbc:mysql://cse6242_team094_mysqldb/cse6242_team094?sessionVariables=sql_mode='NO_ENGINE_SUBSTITUTION'&jdbcCompliantTruncation=false\",\n",
    "                                        driver='com.mysql.jdbc.Driver',\n",
    "                                        dbtable='02b_lda_topic_to_words',\n",
    "                                        user='root',\n",
    "                                        password='p@ssw0rd1')\n",
    "                            .mode('overwrite')\n",
    "                            .save())"
   ]
  },
  {
   "source": [
    "## Load in the Edge Lists from 03-TopicClustering.ipynb\n",
    "\n",
    "The data loaded in here represents the two weighted graphs each for BERTopic and LDA. One graph will represent the topics identified, while the other represents the individual papers."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the edge list from CSV\n",
    "bert_topic_graph = nx.read_edgelist(\"./aws_data/03-bert-topic-graph/topic_graph.csv\", delimiter=\",\", data=True)\n",
    "\n",
    "# Convert the Edge List to Pandas\n",
    "bert_topic_graph_df = nx.to_pandas_edgelist(bert_topic_graph)\n",
    "\n",
    "# Insert the data into MySQL\n",
    "bert_topic_graph_df.to_sql(\"03_bert_topic_graph\", con=dbConnection, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the edge list from CSV\n",
    "bert_paper_graph = nx.read_edgelist(\"./aws_data/03-bert-paper-graph/paper_graph.csv\", delimiter=\",\", data=True)\n",
    "\n",
    "# Convert the Edge List to Pandas\n",
    "bert_paper_graph_df = nx.to_pandas_edgelist(bert_paper_graph)\n",
    "\n",
    "# Insert the data into MySQL\n",
    "bert_paper_graph_df.to_sql(\"03_bert_paper_graph\", con=dbConnection, if_exists='replace', chunksize=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV\n",
    "bert_topic_clust_df = pd.read_csv(\"./aws_data/03-bert-topic-clust-output/bert_topic_clust_output.csv\", sep=\"|\")\n",
    "\n",
    "# Write it to MySQL\n",
    "bert_topic_clust_df.to_sql(\"03_bert_topic_clust_output\", con=dbConnection, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV\n",
    "lda_topic_clust_df = pd.read_csv(\"./aws_data/03-lda-topic-clust-output/lda_topic_clust_output.csv\", sep=\"|\")\n",
    "\n",
    "# Write it to MySQL\n",
    "lda_topic_clust_df.to_sql(\"03_lda_topic_clust_output\", con=dbConnection, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV\n",
    "bert_topic_pagerank_df = pd.read_csv(\"./aws_data/03-bert-topic-pagerank/topic_pagerank.csv\", sep=\"|\")\n",
    "\n",
    "# Write it to MySQL\n",
    "bert_topic_pagerank_df.to_sql(\"03_bert_topic_pagerank\", con=dbConnection, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV\n",
    "lda_topic_pagerank_df = pd.read_csv(\"./aws_data/03-lda-topic-pagerank/topic_pagerank.csv\", sep=\"|\")\n",
    "\n",
    "# Write it to MySQL\n",
    "lda_topic_pagerank_df.to_sql(\"03_lda_topic_pagerank\", con=dbConnection, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV\n",
    "bert_paper_pagerank_df = pd.read_csv(\"./aws_data/03-bert-paper-pagerank/paper_pagerank.csv\", sep=\"|\")\n",
    "\n",
    "# Write it to MySQL\n",
    "bert_paper_pagerank_df.to_sql(\"03_bert_paper_pagerank\", con=dbConnection, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV\n",
    "lda_paper_pagerank_df = pd.read_csv(\"./aws_data/03-lda-paper-pagerank/paper_pagerank.csv\", sep=\"|\")\n",
    "\n",
    "# Write it to MySQL\n",
    "lda_paper_pagerank_df.to_sql(\"03_lda_paper_pagerank\", con=dbConnection, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}